{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T16:43:11.537205Z","iopub.execute_input":"2026-01-24T16:43:11.537960Z","iopub.status.idle":"2026-01-24T16:43:11.546651Z","shell.execute_reply.started":"2026-01-24T16:43:11.537920Z","shell.execute_reply":"2026-01-24T16:43:11.545688Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Importing The Required Libraries ","metadata":{}},{"cell_type":"code","source":"!pip install torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 \\\n  --index-url https://download.pytorch.org/whl/cu121\n!pip install torchtext==0.18.0 --no-deps\n","metadata":{"execution":{"iopub.status.busy":"2026-01-24T17:01:25.030004Z","iopub.execute_input":"2026-01-24T17:01:25.030287Z","iopub.status.idle":"2026-01-24T17:04:25.269006Z","shell.execute_reply.started":"2026-01-24T17:01:25.030260Z","shell.execute_reply":"2026-01-24T17:04:25.267072Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.18.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.3.0+cu121\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0+cu121)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\nInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n  Attempting uninstall: torch\n    Found existing installation: torch 2.8.0+cu126\n    Uninstalling torch-2.8.0+cu126:\n      Successfully uninstalled torch-2.8.0+cu126\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.23.0+cu126\n    Uninstalling torchvision-0.23.0+cu126:\n      Successfully uninstalled torchvision-0.23.0+cu126\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.8.0+cu126\n    Uninstalling torchaudio-2.8.0+cu126:\n      Successfully uninstalled torchaudio-2.8.0+cu126\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\nCollecting torchtext==0.18.0\n  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\nDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchtext\nSuccessfully installed torchtext-0.18.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torchtext\ntorchtext.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:04:36.193185Z","iopub.execute_input":"2026-01-24T17:04:36.193591Z","iopub.status.idle":"2026-01-24T17:04:38.550612Z","shell.execute_reply.started":"2026-01-24T17:04:36.193547Z","shell.execute_reply":"2026-01-24T17:04:38.549687Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'0.18.0+cpu'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch \nimport torchtext \nfrom torchtext import vocab\nfrom torchtext.vocab import GloVe\nimport pandas as pd\nfrom torch.utils.data import DataLoader,Dataset\nfrom torch.nn.utils.rnn import pad_sequence ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:04.789178Z","iopub.execute_input":"2026-01-24T17:05:04.789738Z","iopub.status.idle":"2026-01-24T17:05:05.998787Z","shell.execute_reply.started":"2026-01-24T17:05:04.789703Z","shell.execute_reply":"2026-01-24T17:05:05.997554Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \nTorchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Loading The Data","metadata":{}},{"cell_type":"code","source":" data=pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:09.335150Z","iopub.execute_input":"2026-01-24T17:05:09.335779Z","iopub.status.idle":"2026-01-24T17:05:10.765748Z","shell.execute_reply.started":"2026-01-24T17:05:09.335741Z","shell.execute_reply":"2026-01-24T17:05:10.764254Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data[\"sentiment\"] = data[\"sentiment\"].map({\n    \"negative\": 0,\n    \"positive\": 1\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:13.812294Z","iopub.execute_input":"2026-01-24T17:05:13.812809Z","iopub.status.idle":"2026-01-24T17:05:13.827901Z","shell.execute_reply.started":"2026-01-24T17:05:13.812755Z","shell.execute_reply":"2026-01-24T17:05:13.826631Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:14.459309Z","iopub.execute_input":"2026-01-24T17:05:14.459710Z","iopub.status.idle":"2026-01-24T17:05:14.471484Z","shell.execute_reply.started":"2026-01-24T17:05:14.459678Z","shell.execute_reply":"2026-01-24T17:05:14.470422Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  review  sentiment\n0      One of the other reviewers has mentioned that ...          1\n1      A wonderful little production. <br /><br />The...          1\n2      I thought this was a wonderful way to spend ti...          1\n3      Basically there's a family where a little boy ...          0\n4      Petter Mattei's \"Love in the Time of Money\" is...          1\n...                                                  ...        ...\n49995  I thought this movie did a down right good job...          1\n49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n49997  I am a Catholic taught in parochial elementary...          0\n49998  I'm going to have to disagree with the previou...          0\n49999  No one expects the Star Trek movies to be high...          0\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"class CSVDataset(Dataset):\n    def __init__(self,dataframe):\n        self.df=dataframe.reset_index(drop=True)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        review=self.df.iloc[idx]['review']\n        label=torch.tensor(self.df.iloc[idx]['sentiment'],dtype=torch.long)\n        return review,label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:15.072708Z","iopub.execute_input":"2026-01-24T17:05:15.074463Z","iopub.status.idle":"2026-01-24T17:05:15.081351Z","shell.execute_reply.started":"2026-01-24T17:05:15.074401Z","shell.execute_reply":"2026-01-24T17:05:15.079970Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,test_df=train_test_split(data,test_size=0.2,random_state=42)\ntrain_dataset=CSVDataset(train_df)\ntest_dataset=CSVDataset(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:17.163504Z","iopub.execute_input":"2026-01-24T17:05:17.163945Z","iopub.status.idle":"2026-01-24T17:05:18.776597Z","shell.execute_reply.started":"2026-01-24T17:05:17.163913Z","shell.execute_reply":"2026-01-24T17:05:18.775344Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataloader=DataLoader(train_dataset,batch_size=32,shuffle=True)\ntest_dataloader=DataLoader(test_dataset,batch_size=32,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:18.778290Z","iopub.execute_input":"2026-01-24T17:05:18.778825Z","iopub.status.idle":"2026-01-24T17:05:18.784991Z","shell.execute_reply.started":"2026-01-24T17:05:18.778792Z","shell.execute_reply":"2026-01-24T17:05:18.783502Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"reviews,labels=next(iter(train_dataloader))\nprint(reviews[0],labels[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:19.162822Z","iopub.execute_input":"2026-01-24T17:05:19.163253Z","iopub.status.idle":"2026-01-24T17:05:19.185474Z","shell.execute_reply.started":"2026-01-24T17:05:19.163219Z","shell.execute_reply":"2026-01-24T17:05:19.183940Z"}},"outputs":[{"name":"stdout","text":"I really loved this movie and so did the audience that I saw it with in Los Angeles. After the film, lots of people were crying and saying how much the film had affected them. I can see why it was such a huge hit in its homeland, Sweden. The film is masterfully directed and each character brilliantly drawn so that by the end you really know these people and care about them. The music is very natural and the main song in the film quite heartbreaking but inspiring. Would definitely recommend this film for everyone to see - even people who don't normally go to subtitled films. Definitely deserved the Oscar Nomination because of the profound themes of the film reflected without pretension in a small-town community with everyday people. It is a film that unites us in this divided world and shows us the potential of the human spirit. A MUST SEE! tensor(1)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Getting Glove Embeddings and Indexes","metadata":{}},{"cell_type":"code","source":"glove=GloVe(name=\"6B\",dim=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:05:20.392657Z","iopub.execute_input":"2026-01-24T17:05:20.393031Z","iopub.status.idle":"2026-01-24T17:10:09.037817Z","shell.execute_reply.started":"2026-01-24T17:05:20.393000Z","shell.execute_reply":"2026-01-24T17:10:09.036301Z"}},"outputs":[{"name":"stderr","text":".vector_cache/glove.6B.zip: 862MB [04:09, 3.46MB/s]                               \n100%|█████████▉| 399999/400000 [00:14<00:00, 28071.78it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch.nn as nn\nembeddings=nn.Embedding.from_pretrained(glove.vectors,freeze=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:10:09.040343Z","iopub.execute_input":"2026-01-24T17:10:09.040764Z","iopub.status.idle":"2026-01-24T17:10:09.047013Z","shell.execute_reply.started":"2026-01-24T17:10:09.040730Z","shell.execute_reply":"2026-01-24T17:10:09.045955Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nimport nltk\ntokenizer=get_tokenizer(\"basic_english\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:16:28.041856Z","iopub.execute_input":"2026-01-24T17:16:28.043218Z","iopub.status.idle":"2026-01-24T17:16:28.049061Z","shell.execute_reply.started":"2026-01-24T17:16:28.043167Z","shell.execute_reply":"2026-01-24T17:16:28.047669Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"word_to_index=glove.stoi\nindex_to_word=glove.itos\nvocab = torchtext.vocab.vocab(glove.stoi, 0,specials=('<unk>', '<pad>'))\nvocab.set_default_index(vocab[\"<unk>\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:27:49.525979Z","iopub.execute_input":"2026-01-24T17:27:49.526565Z","iopub.status.idle":"2026-01-24T17:27:49.912546Z","shell.execute_reply.started":"2026-01-24T17:27:49.526478Z","shell.execute_reply":"2026-01-24T17:27:49.911610Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"vocab_size=len(vocab)\nvocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:04:55.444124Z","iopub.execute_input":"2026-01-24T18:04:55.444546Z","iopub.status.idle":"2026-01-24T18:04:55.453857Z","shell.execute_reply.started":"2026-01-24T18:04:55.444491Z","shell.execute_reply":"2026-01-24T18:04:55.452439Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"400002"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:37:43.644042Z","iopub.execute_input":"2026-01-24T17:37:43.645041Z","iopub.status.idle":"2026-01-24T17:37:43.653003Z","shell.execute_reply.started":"2026-01-24T17:37:43.644999Z","shell.execute_reply":"2026-01-24T17:37:43.651976Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def text_pipeline(x):\n    return vocab(tokenizer(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T17:29:35.704863Z","iopub.execute_input":"2026-01-24T17:29:35.705237Z","iopub.status.idle":"2026-01-24T17:29:35.711296Z","shell.execute_reply.started":"2026-01-24T17:29:35.705204Z","shell.execute_reply":"2026-01-24T17:29:35.709884Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"max_len=256\ndef collate_batch(batch):\n    label_list=[]\n    text_list=[]\n    for _text,_label in  batch:\n        label_list.append(_label)\n        text_list.append(torch.tensor(text_pipeline(_text)[:max_len],dtype=torch.int64))\n    label_list=torch.tensor(label_list,dtype=torch.int64)\n    text_list=pad_sequence(text_list,batch_first=True)\n    return label_list.to(device),text_list.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:18.226890Z","iopub.execute_input":"2026-01-24T18:24:18.227428Z","iopub.status.idle":"2026-01-24T18:24:18.235807Z","shell.execute_reply.started":"2026-01-24T18:24:18.227389Z","shell.execute_reply":"2026-01-24T18:24:18.234234Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ntrain_dataloader = DataLoader(\n    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:21.870665Z","iopub.execute_input":"2026-01-24T18:24:21.871959Z","iopub.status.idle":"2026-01-24T18:24:21.878565Z","shell.execute_reply.started":"2026-01-24T18:24:21.871905Z","shell.execute_reply":"2026-01-24T18:24:21.877226Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"label,sequence=next(iter(train_dataloader))\nlabel,sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:22.747893Z","iopub.execute_input":"2026-01-24T18:24:22.749053Z","iopub.status.idle":"2026-01-24T18:24:22.781947Z","shell.execute_reply.started":"2026-01-24T18:24:22.749005Z","shell.execute_reply":"2026-01-24T18:24:22.780697Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"(tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n         0, 0, 0, 1, 1, 1, 1, 0]),\n tensor([[  50,    5,    2,  ...,    2, 1086,  415],\n         [4758, 4329, 7085,  ...,    0,    0,    0],\n         [  39,  275,  909,  ...,    0,    0,    0],\n         ...,\n         [ 367, 1139, 8631,  ...,    0,    0,    0],\n         [  39,    9, 5207,  ...,    0,    0,    0],\n         [  43,   35,    6,  ..., 3318,   59, 2161]]))"},"metadata":{}}],"execution_count":90},{"cell_type":"markdown","source":"## Defining Normal Architecture of the Model","metadata":{}},{"cell_type":"code","source":"import math\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=512, dropout=0.1):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n        )\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n        self.register_buffer(\"pe\", pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return self.dropout(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:25.264353Z","iopub.execute_input":"2026-01-24T18:24:25.265598Z","iopub.status.idle":"2026-01-24T18:24:25.274919Z","shell.execute_reply.started":"2026-01-24T18:24:25.265462Z","shell.execute_reply":"2026-01-24T18:24:25.273785Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(\n\n        self,\n        num_class,vocab_size,\n        freeze=True,\n        nhead=2,\n        dim_feedforward=128,\n        num_layers=2,\n        dropout=0.1,\n        activation=\"relu\",\n        classifier_dropout=0.1):\n\n        super().__init__()\n\n        self.emb = nn.Embedding.from_pretrained(glove.vectors,freeze=freeze)\n        embedding_dim = self.emb.embedding_dim\n\n\n        self.pos_encoder = PositionalEncoding(\n            d_model=embedding_dim,\n            dropout=dropout,\n            max_len=256\n        )\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embedding_dim,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n        )\n        self.transformer_encoder = nn.TransformerEncoder(\n            encoder_layer,\n            num_layers=num_layers,\n        )\n        self.classifier = nn.Linear(embedding_dim, num_class)\n        self.d_model = embedding_dim\n\n    def forward(self, x):\n        x = self.emb(x) * math.sqrt(self.d_model)\n        x = self.pos_encoder(x)\n        x = self.transformer_encoder(x)\n        x = x.mean(dim=1)\n        x = self.classifier(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:26.889874Z","iopub.execute_input":"2026-01-24T18:24:26.890246Z","iopub.status.idle":"2026-01-24T18:24:26.900157Z","shell.execute_reply.started":"2026-01-24T18:24:26.890213Z","shell.execute_reply":"2026-01-24T18:24:26.898885Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Net(num_class=2,vocab_size=vocab_size).to(device)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:28.347062Z","iopub.execute_input":"2026-01-24T18:24:28.347454Z","iopub.status.idle":"2026-01-24T18:24:28.365704Z","shell.execute_reply.started":"2026-01-24T18:24:28.347417Z","shell.execute_reply":"2026-01-24T18:24:28.364471Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"Net(\n  (emb): Embedding(400000, 50)\n  (pos_encoder): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=50, out_features=50, bias=True)\n        )\n        (linear1): Linear(in_features=50, out_features=128, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=128, out_features=50, bias=True)\n        (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (classifier): Linear(in_features=50, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"imdb_label={0:\"negative\",1:\"positive\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:29.920928Z","iopub.execute_input":"2026-01-24T18:24:29.922190Z","iopub.status.idle":"2026-01-24T18:24:29.927631Z","shell.execute_reply.started":"2026-01-24T18:24:29.922148Z","shell.execute_reply":"2026-01-24T18:24:29.926133Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"def predict(text, text_pipeline, model):\n    with torch.no_grad():\n        text = torch.unsqueeze(torch.tensor(text_pipeline(text)),0).to(device)\n        model.to(device)\n        output = model(text)\n        return imdb_label[output.argmax(1).item()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:32.279993Z","iopub.execute_input":"2026-01-24T18:24:32.280402Z","iopub.status.idle":"2026-01-24T18:24:32.287132Z","shell.execute_reply.started":"2026-01-24T18:24:32.280360Z","shell.execute_reply":"2026-01-24T18:24:32.286095Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"predict(\"I like sports and stuff\", text_pipeline, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:24:33.245263Z","iopub.execute_input":"2026-01-24T18:24:33.246331Z","iopub.status.idle":"2026-01-24T18:24:33.258768Z","shell.execute_reply.started":"2026-01-24T18:24:33.246281Z","shell.execute_reply":"2026-01-24T18:24:33.257651Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"'positive'"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"from tqdm.auto import tqdm\ndef evaluate(dataloader, model_eval):\n    model_eval.eval()\n    total_acc, total_count= 0, 0\n\n    with torch.no_grad():\n        for label, text in dataloader:\n            label, text = label.to(device), text.to(device)\n            output = model_eval(text)\n            predicted = torch.max(output.data, 1)[1]\n            total_acc += (predicted == label).sum().item()\n            total_count += label.size(0)\n    return total_acc / total_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:27:26.242052Z","iopub.execute_input":"2026-01-24T18:27:26.242438Z","iopub.status.idle":"2026-01-24T18:27:26.249438Z","shell.execute_reply.started":"2026-01-24T18:27:26.242394Z","shell.execute_reply":"2026-01-24T18:27:26.248547Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"import os\nimport time \ndef train_model(model, optimizer, criterion, train_dataloader, test_dataloader,  epochs=1000, save_dir=\"\", file_name=None):\n    cum_loss_list = []\n    acc_epoch = []\n    acc_old = 0\n    model_path = os.path.join(save_dir, file_name)\n    acc_dir = os.path.join(save_dir, os.path.splitext(file_name)[0] + \"_acc\")\n    loss_dir = os.path.join(save_dir, os.path.splitext(file_name)[0] + \"_loss\")\n    time_start = time.time()\n\n    for epoch in tqdm(range(1, epochs + 1),desc=\"Epochs\", total=epochs):\n        model.train()\n        \n        cum_loss = 0\n        for idx, (label, text) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n            label, text = label.to(device), text.to(device)\n\n            predicted_label = model(text)\n            loss = criterion(predicted_label, label)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n            optimizer.step()\n            cum_loss += loss.item()\n        print(f\"Epoch {epoch}/{epochs} - Loss: {cum_loss}\")\n\n        cum_loss_list.append(cum_loss)\n        accu_val = evaluate(test_dataloader,model)\n        acc_epoch.append(accu_val)\n\n        if model_path and accu_val > acc_old:\n            print(accu_val)\n            acc_old = accu_val\n            if save_dir is not None:\n                pass\n                \n    time_end = time.time()\n    print(f\"Training time: {time_end - time_start}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:27:30.200189Z","iopub.execute_input":"2026-01-24T18:27:30.200589Z","iopub.status.idle":"2026-01-24T18:27:30.213667Z","shell.execute_reply.started":"2026-01-24T18:27:30.200547Z","shell.execute_reply":"2026-01-24T18:27:30.212109Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"import time \nLR=1\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\nsave_dir = \"\"\nfile_name = \"model_IMDB dataset small2.pth\"\ntrain_model(model=model, \n            optimizer=optimizer, \n            criterion=criterion, \n            train_dataloader=train_dataloader, \n            test_dataloader=test_dataloader, \n            epochs=2, \n            save_dir=save_dir, \n            file_name=file_name\n           )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T18:27:31.429775Z","iopub.execute_input":"2026-01-24T18:27:31.430191Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d983bad933043938095059f33d34302"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/2 - Loss: 834.4990931749344\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f44e35284d41158beea2b66643a3da"}},"metadata":{}},{"name":"stdout","text":"0.6291\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}